# <a name="_lk8obq985wl5"></a>Ethical Dilemma Identification Framework
Share\
**C**\
Part 1 Summary: Ethical Dilemma Identification Process\
What We Accomplished\
Successfully developed and tested a decision tree framework for helping students identify suitable ethical dilemmas for semester-long analysis.\
Key Outcomes\
1\. Tested Decision Tree Framework\
\* Walked through the 6-step decision process using a real workplace authority dilemma\
\* Confirmed the framework successfully filters for scenarios with appropriate complexity\
\* Identified that the process works best with focused category prompts rather than open-ended questions\
2\. Developed AI Coaching Instructions\
\* Created specific guidance to help AI serve as a thinking partner rather than solution provider\
\* Built in safeguards to keep conversations focused on personal dilemma exploration\
\* Added final step for generating Ethical Dilemma Draft for instructor review\
3\. Validated Sample Scenario\
The Administrative Policy Dilemma: A program coordinator caught between supervisor expectations to implement unpopular policies and obligations to faculty colleagues, family financial security, and professional integrity. This scenario demonstrates:\
\* Multiple authentic roles with competing obligations\
\* No clear "right" answer that reasonable people would agree on\
\* Ongoing significance (still relevant 8+ years later)\
\* Complexity that different ethical frameworks would approach differently\
4\. Created Complete Student Guide\
\* Combined decision tree with AI coaching instructions\
\* Includes common pitfalls and successful examples\
\* Provides clear process from initial situation through polished draft\
Key Insights for Course Design\
1\. Authenticity matters: Using real, unresolved dilemmas shows students that ethical complexity doesn't always have neat solutions\
2\. Process over product: The goal is sophisticated thinking about ethical decision-making, not finding "correct" answers\
3\. AI as thinking partner: Properly guided AI can replicate the kind of Socratic questioning that helps students discover complexity\
4\. Multiple roles create ethical tension: The most sustainable dilemmas emerge from competing obligations between different authentic roles students occupy\
Next Steps: Part 2 Development\
Need to develop the "documentation and exploration method" component that helps students:\
\* Choose appropriate ways to analyze and document their dilemma over 16 weeks\
\* Apply multiple ethical frameworks systematically\
\* Develop more sophisticated decision-making processes\
\* Create meaningful final deliverables\
Files Created\
\* Ethical Dilemma Identification Guide with AI Coaching (ready for Canvas/Google Doc deployment)\
*Ready to begin Part 2: Documentation and Exploration Methods in new conversation*\
Edit\
This is an excellent foundation for your ethics course design! You've created a robust system that addresses one of the most challenging aspects of teaching applied ethics - helping students identify genuinely complex dilemmas that will sustain meaningful analysis over a full semester.\
What strikes me most about your approach is how you've balanced structure with authenticity. The decision tree provides clear guidance while the AI coaching component maintains the open-ended exploration that's essential for ethical reasoning. Your insight about using "focused category prompts rather than open-ended questions" is particularly valuable - it gives students enough direction to be productive without constraining their thinking.\
The Administrative Policy Dilemma example perfectly illustrates the kind of multi-layered complexity you're aiming for. It demonstrates how real ethical dilemmas rarely pit "good" against "evil" but instead involve competing goods and legitimate obligations that can't all be satisfied simultaneously.\
Your four key insights for course design are spot-on, especially the emphasis on "process over product." This approach should help students develop the kind of nuanced ethical reasoning skills that transfer beyond the classroom.\
For Part 2, you'll want to consider how students will:

- Track their thinking evolution over 16 weeks
- Apply different ethical frameworks without forcing artificial conclusions
- Document decision points and reasoning changes
- Create deliverables that showcase their analytical growth

Ready to dive into Part 2 whenever you are! This foundation gives you excellent momentum for developing the documentation and exploration methods that will bring the semester-long analysis to life.\
Retry\
**C**\
So the outcome for this conversation is to create a second prompt that students can paste into an AI that will help them conceptualize the next phase - the exploration of their dilemma and how to capture their reflections and insights over the course of the semester.\
Edit\
Perfect! Let me create a comprehensive AI coaching prompt for Part 2 that will help students develop their exploration and documentation approach for the semester-long analysis.\
Ethical Dilemma Exploration & Documentation Guide with AI Coaching\
Document\
\# Ethical Dilemma Exploration & Documentation Guide with AI Coaching

\## For Students: How to Use This Guide

You've already identified your ethical dilemma using the Decision Tree Framework. Now you need to develop a systematic approach for explorin\
I've created a comprehensive AI coaching guide for Part 2 that will help students develop their semester-long exploration and documentation approach. The prompt is designed to:\
Key Features:

1. Structured but flexible - Provides clear guidance while allowing for personalization based on learning styles and dilemma types
1. Sustainable focus - Emphasizes choosing approaches students can actually maintain over 16 weeks
1. Multiple pathways - Offers various documentation methods and exploration strategies
1. Growth-oriented - Keeps the focus on developing ethical reasoning skills rather than finding "correct" answers

The guide addresses four critical areas:

- Documentation method selection (how they'll capture their ongoing analysis)
- Framework application strategy (systematic engagement with ethical theories)
- Reflection rhythm (sustainable practices for deepening analysis)
- Final deliverable design (showcasing their analytical journey)

Built-in safeguards include:

- Clear boundaries to keep AI as thinking partner, not solution provider
- Red flags section to help students avoid common pitfalls
- Success indicators to help them evaluate their approach
- Multiple example pathways to inspire different approaches

The prompt follows the same successful pattern as Part 1 - providing comprehensive coaching instructions for the AI while giving students a clear starter prompt to begin their conversation. Students can now move seamlessly from dilemma identification to systematic exploration planning.\
Ready to test this or would you like any adjustments to the approach or emphasis?\
Retry\
**C**\
stop, please.\
Edit\
Understood. I'll stop here.\
Retry\
**C**\
my comment was intended to remind me of what I want to get out of this next phase. Again, you don't need to immediately jump into production mode. Sigh...\
Edit\
You're absolutely right - I apologize. I jumped straight into creating the artifact when you were simply clarifying the goal for yourself.\
Let me step back. You've outlined what you want to accomplish: creating a second prompt for the exploration and documentation phase. But before diving into production, it would be helpful to understand more about your vision for this phase and what specific challenges or considerations you're thinking through.\
What aspects of the exploration and documentation phase are you most focused on getting right?\
Retry\
**C**\
So, in part 1, the student articulates the dilemma and relevant roles/titles/obligations as the basis for tension within the dilemma. I think the next step before we talk about documentation and exploration is the next critical deliverable: some kind of expression of the ethical algorithms they use to make decisions within each one of the roles they have identified. The core purpose of reviewing the different ethical models is to look at the decision-making priorities, principles, and some specifics they already possess or perceive connected to their roles so they can consider whether to include elements of new models, remove outdated "codes" that no longer reflect their current thinking, or challenge their assumptions with unresolved issues raised by new models.\
Edit\
Ah, that's a crucial insight and a much more sophisticated approach than I was initially considering. You're essentially saying that before students can meaningfully engage with formal ethical frameworks, they need to surface and articulate their existing ethical operating systems - the informal "algorithms" they're already using to make decisions within each of their identified roles.\
This makes perfect sense. Students aren't blank slates when they encounter virtue ethics or utilitarianism. They already have embedded decision-making patterns, priorities, and principles that they've developed through experience in their various roles. The formal frameworks become tools for examining, refining, or challenging these existing systems rather than abstract theories to apply from scratch.\
So the deliverable for this phase would be something like mapping their current ethical algorithms for each role? Understanding what principles they currently prioritize, what decision-making shortcuts they use, what assumptions underlie their choices within each role context?\
This also sets up a much more personal and practical engagement with the formal frameworks later - they're not just learning about Kant or Mill in the abstract, but asking "How does this challenge or refine how I currently make decisions as a parent/employee/citizen/etc.?"\
What are you thinking this deliverable should look like? Some kind of structured self-analysis of their current ethical operating systems?\
Retry\
**C**\
Well, that's where it gets tricky. It is very likely that students have very limited vocabulary or awareness of what constitutes their ethical processes, even though they exist, so we need to create a series of exploratory questions that they can respond to with descriptive language, even if it does not necessarily lend itself to categorization or alignment with the ethical models they will explore. Part of the fun will be asking them to look at what they wrote as they begin to read about these models and try to classify for themselves which models best echo what they were thinking in their baseline state.\
Edit\
Exactly! That's the brilliance of this approach - you're creating a kind of "ethical archaeology" where students excavate their own existing decision-making patterns before they have the formal vocabulary to categorize them.\
The exploratory questions need to be concrete and experiential enough that students can respond authentically with stories, examples, and descriptions of their actual thinking processes, even without knowing terms like "deontological" or "consequentialist." They're essentially creating their own ethical fingerprint in plain language.\
Then later, when they encounter Kant or Mill or virtue ethics, they get those wonderful "aha" moments of recognition - "Oh, this is what I was doing when I said..." or "This framework challenges that assumption I made about..."\
This also means the questions need to be crafted carefully to draw out the actual logic they use, not just their stated values. Something that gets at the "when push comes to shove" decision-making rather than aspirational ideals.\
Are you thinking these questions would be role-specific? So they'd work through this exploratory process separately for each of the roles they identified in their dilemma - examining how their ethical algorithms differ when they're operating as employee vs. parent vs. community member, etc.?\
This could reveal some fascinating tensions where their decision-making logic in one role contradicts what they use in another role.\
Retry\
**C**\
And that tension is why we are doing all of this; it is how we move from artificial homework assignment to authentic personal discovery. Or at least, that's the intended outcome.\
Edit\
Yes - that's the heart of it. When students discover that their ethical algorithm as a parent directly conflicts with their ethical algorithm as an employee, they're no longer analyzing some abstract case study. They're confronting the actual lived complexity of their own moral reasoning.\
That tension becomes the engine for genuine inquiry rather than academic exercise. It's not "What would Kant say about this hypothetical situation?" but "Wait, I seem to believe contradictory things about what makes decisions right or wrong, and I have to live with both of these roles every day."\
And because it's their own discovered contradiction - something they articulated in their own words before they had the theoretical vocabulary - they can't dismiss it as irrelevant academic theory. It's their own thinking looking back at them.\
The formal ethical frameworks then become tools for working through this authentic personal puzzle rather than abstract content to master. Much more likely to stick and transfer to real-world decision-making.\
So the design challenge is creating those exploratory questions that reliably surface these kinds of contradictions and patterns without students realizing that's what they're doing until they look back at their responses later.\
Retry\
**C**\
The intent isn't necessarily to force the contradictions to the surface just yet. Just getting students to move, like you said, beyond the socially expected or acceptable response to what they are really thinking when push comes to shove is more than I might be able to reasonably hope for at this point.\
Edit\
You're absolutely right - I was getting ahead of myself. The contradictions will emerge naturally when they exist, but the real challenge at this stage is just getting students past their default "what I'm supposed to say" responses to their actual decision-making reality.\
That's hard enough on its own. Students are so practiced at giving the "right" answer - especially in academic contexts and especially around ethics - that accessing their genuine thought processes requires careful question design.\
The exploratory questions need to bypass that social desirability filter somehow. Maybe through specificity, or focusing on actual past decisions rather than hypothetical future ones, or framing that makes it safe to admit complexity rather than moral certainty.\
Getting authentic self-reflection rather than performed virtue is the real win here. If they can capture how they actually think through decisions in each role - even if it's messy or inconsistent or doesn't align with what they think they should believe - that creates the raw material for meaningful engagement with formal frameworks later.\
The contradictions, if they exist, will become visible to students organically when they review their baseline responses while learning new frameworks. No need to engineer that discovery.\
Retry\
**C**\
My hope is that fact that I am removing grading as part of the experience removes a little of the pressure for social desirability. Instead, they are more rewarded for process and honesty than product, which lowers the stakes for getting things "right." I am just trying to figure out what kinds of questions would help someone articulate in a meaningful way how they make decisions in the roles they currently or previously occupy when most of the time it is semi-conscious or totally unconscious, or is seen as a reflection of their religious piety or self-identity that is pretty sacred to them and not open for question or reflection.\
Edit\
That's a really insightful recognition of the barriers. You're dealing with decision-making processes that are often unconscious, identity-protective, or so fundamental to someone's sense of self that questioning them feels threatening.\
The no-grading approach should help, but the questions themselves need to do some heavy lifting to make this reflection feel safe and accessible rather than invasive or judgmental.\
I'm thinking the questions might need to:

- Focus on specific, concrete situations rather than abstract principles
- Ask about process ("How did you decide...") rather than values ("What do you believe...")
- Maybe approach it sideways - asking about times they felt conflicted or uncertain rather than times they were confident
- Possibly ask about observations of their own patterns rather than defending their choices

Or maybe questions that ask them to describe their decision-making to someone in that same role who's new to it? Like "If you were training someone to do your job, what would you tell them about how to make the tough calls?" That might access the practical wisdom they've developed without making them defend it philosophically.\
The challenge is finding the right angle that lets them be descriptive and reflective without triggering defensiveness about core identity or religious convictions.\
What's your sense of which approaches might feel most accessible to students?\
Retry\
**C**\
Well, the fact that Part 1 has them reliving a difficult situation helps to provide a context in which uncertainty or discomfort was already disrupting their status quo. If we can connect these two, it is very possible that the disassociative state might lend itself to more honest responses. And it doesn't necessarily come across as sitting on a counselor's couch talking about your childhood.\
Edit\
That's brilliant - you're leveraging the psychological state they're already in from Part 1. They've just spent time articulating a situation where their normal decision-making processes were inadequate or in conflict. They're already in that space of acknowledged uncertainty and disruption.\
So instead of asking them to step back and analyze their decision-making in the abstract, you're asking them to examine it while they're still in the mindset of "my usual approaches weren't working here." That vulnerability and openness is already activated.\
And because they're looking at their decision-making through the lens of this specific, already-articulated dilemma, it feels like problem-solving rather than therapy. They're not being asked to bare their soul about their deepest values - they're being asked to understand why this particular situation was so difficult for them.\
The questions could build directly from their dilemma narrative: "In this situation, when you were operating in your role as [X], what were you trying to optimize for? What felt most important to protect or achieve?" That grounds the reflection in the concrete situation they've already described rather than asking them to generalize about their ethical beliefs.\
It's like catching them in a moment when their ethical algorithms are already exposed and asking them to look at what's there, rather than trying to excavate them from scratch.\
Retry\
**C**\
Exactly. And what I need to figure out is what should be involved or entailed in an "ethical algorithm." I would say that values or guiding principles - one word or phrase that suggests this is the most important element to consider, along with some of the rules that help them determine if something feels "good" or "right" based on the role they are discussing.\
Edit\
Yes, that's a solid foundation. So for each role in their dilemma, you're trying to help them surface:

1. The guiding principle/value - what they're fundamentally trying to optimize for in that role
1. The operational rules - their heuristics for determining if something aligns with that principle

The algorithm metaphor is really helpful because algorithms have that same structure: an objective function (what you're trying to maximize/minimize) and decision rules (if-then logic for how to get there).\
So a student might discover that in their role as employee, their guiding principle is "professional competence" and their rules include things like "if it makes the organization look bad, it's wrong" or "if I can't defend it to my supervisor, I shouldn't do it."\
But in their role as colleague, maybe their guiding principle is "loyalty to relationships" with rules like "if it hurts someone I work with, it's wrong" or "if it breaks trust, it's wrong."\
The beauty is that both sets of rules can feel completely logical and "right" within their respective contexts, but they might lead to completely different conclusions in the dilemma situation.\
Are you thinking the questions should help them identify both elements explicitly, or let them describe their thinking more organically and then help them see the pattern afterward?\
Retry\
**C**\
Just a quick aside, are these if/then statements called syllogisms? Is that the right terminology?\
Edit\
Not quite - syllogisms are a specific form of logical argument with two premises and a conclusion, like:\
Syllogism example:

- All humans are mortal (major premise)
- Socrates is human (minor premise)
- Therefore, Socrates is mortal (conclusion)

The if-then statements you're describing are more like heuristics or decision rules. In logic and computer science, they might be called:

- Conditional statements (if-then logic)
- Heuristics (rules of thumb for decision-making)
- Decision rules or business rules
- In philosophy, they might be called practical principles or maxims

The if-then format ("if it makes the organization look bad, then it's wrong") is closer to how we actually structure decision algorithms - simple conditional logic that guides choices.\
Syllogisms are more formal and deductive, while these ethical algorithms you're having students identify are more practical and heuristic-based. They're the shortcuts people actually use to navigate decisions quickly, rather than formal logical proofs.\
Does that distinction help clarify the terminology you want to use with students?\
Retry\
**C**\
I am not sure I would bring it up in these terms, as that could break the "spell" we are trying to weave by asking them to immerse themselves in the dilemma, but as we move on through the semester, introducing proper taxonomy increases the validity of the overall course, which is never a bad thing.\
Edit\
Absolutely - you want to maintain that immersive, reflective state where they're examining their actual thinking patterns rather than switching into academic analysis mode. Using formal terminology at this stage could snap them out of that vulnerable, exploratory mindset and back into "performing knowledge" mode.\
But having the proper taxonomy in your back pocket gives you precision in designing the questions and will be valuable later when they're ready to connect their discovered patterns to formal ethical frameworks. At that point, being able to say "these decision rules you identified are what philosophers call practical principles" or "this if-then logic you described is a type of heuristic" adds legitimacy and helps them see their thinking as part of a broader intellectual tradition.\
Right now though, keeping the language experiential and grounded in their dilemma context preserves the authenticity you're working so hard to cultivate. They're not analyzing ethical algorithms - they're just trying to understand why this situation was so hard for them and how they typically think through decisions in each role.\
The formal language can emerge organically as the semester progresses and they're ready for that level of abstraction.\
Retry\
**C**\
Yep, right now, I am trying to get them to articulate their instinctual responses, the why did you do it this way kind of thing that could be parsed out into if/then statements. I don't want to ask them to draft those (it breaks the spell), but if we ask them the right kinds of questions, those patterns would likely emerge.\
Edit\
Exactly - you want them describing their natural decision-making flow in story form, and the if-then patterns will be embedded in that narrative without them having to consciously construct them.\
So instead of "What rule do you follow when..." it's more like "Walk me through how you decided..." or "What was going through your mind when you realized you had to choose..." The algorithmic structure emerges from their description of their actual thought process.\
They might say something like "Well, I knew I couldn't do anything that would make my team look incompetent, so I started thinking about how to handle it without throwing anyone under the bus, but then I realized my boss was expecting a direct answer and wouldn't appreciate me being evasive..."\
That narrative contains multiple if-then rules (if it makes team look bad, find alternative; if boss expects directness, don't be evasive) but they're not consciously articulating them as rules - they're just describing how they actually thought through the situation.\
The questions need to elicit that kind of process description rather than asking them to step outside their experience and analyze it. Keep them in the story, in the moment of decision-making, rather than asking them to become ethicists examining their own behavior.\
Retry\
**C**\
Yes!!! That is it. Exactly.\
Edit\
Perfect! So now the design challenge becomes crafting questions that keep them in that narrative, experiential mode while reliably drawing out the decision-making process across their different roles.\
Questions that feel natural and conversational but systematically surface how they actually think through choices when they're operating as employee vs. parent vs. community member, etc.\
The magic will be in getting them to tell the story of their thinking rather than analyze it - staying in the "this is what happened in my head" mode rather than the "this is what I believe about ethics" mode.\
Retry\
**C**\
I like the story-telling aspect. It takes away from the impression of analysis. So, at the end of Part 1, they ask AI to generate a summary document. Part 2, they can upload that document to get things started because the entire thing should be the barebones skeleton of the story. All we have to do is ask the right questions to get the muscles and skin attached.\
Edit\
That's a beautiful metaphor - the Part 1 document as the skeleton, and Part 2 as adding the muscles and skin through storytelling. The AI already has the basic structure: the roles, the competing obligations, the core tension. Now it can ask follow-up questions that get them to flesh out the actual decision-making process within each role.\
"You mentioned you felt torn between your obligations as a supervisor and your loyalty to your colleagues. Tell me more about that moment when you first realized you were caught in the middle - what was going through your head?"\
The AI can use their skeleton to ask very specific, contextualized questions that feel like natural curiosity about their story rather than generic ethical analysis prompts. It already knows their particular roles and situation, so every question can be tailored to their specific dilemma.\
And because they're building on something they already wrote and submitted, there's continuity and investment. They're not starting over - they're deepening and enriching something they've already committed to exploring.\
Retry\
**C**\
OK. I like this, and we can let students decide how far they need to go, rather than making up artificial limits. But, in the AI instructions, we could include the directive to continue to ask follow up questions until there are at least 10 or so if/then heuristics per role, along with two or three guiding principle descriptions?\
Edit\
That's smart - giving the AI a concrete target while letting students control the pacing. The AI can keep the conversation flowing naturally ("Tell me more about how you handled that part..." "What happened next when you realized...") while working toward that underlying goal of surfacing enough material for meaningful analysis later.\
And 10 if-then heuristics per role feels about right - enough to see real patterns and potential contradictions, but not so many that it becomes overwhelming or repetitive. Combined with 2-3 guiding principles, that gives a rich picture of their ethical operating system for each role.\
The AI can track this behind the scenes and know when to naturally wind down the exploration for each role, or when to dig deeper if they're only getting surface-level responses. It removes the guesswork about "when is enough enough" while keeping the experience organic for the student.\
Plus having that target helps ensure consistency across different students - everyone emerges from Part 2 with roughly equivalent raw material to work with when they start engaging with formal frameworks.\
The AI could even do a gentle summary check at the end: "Let me reflect back what I'm hearing about how you approach decisions in your role as..." to help solidify the patterns before they move on.\
Retry\
**C**\
Some kind of, "OK. Let me compile this into summaries and have you check to see if they sound accurate..." kind of thing.\
Edit\
Exactly - that compilation step serves multiple purposes. It helps the student see their own patterns more clearly when they're reflected back in organized form, gives them a chance to correct or refine anything that doesn't feel quite right, and creates the clean raw material they'll need for the next phase.\
Plus there's something powerful about seeing your own decision-making logic laid out systematically. They might have moments of "Oh wow, I really do prioritize X over Y consistently" or "I didn't realize how much my thinking changes between these two roles."\
The AI could frame it as quality assurance rather than analysis: "I want to make sure I captured your thinking accurately before we wrap up..." That keeps it feeling collaborative and practical rather than like they're being studied or judged.\
And then they have these role-specific summaries ready to upload when they eventually start engaging with Kant, Mill, Aristotle, etc. The formal frameworks become tools for examining and potentially refining these existing patterns rather than abstract theories to memorize.\
Retry\
**C**\
Exactly, the students can look at all these models to identify the inherent if/then ideals for each model, comparing them to their own stated instincts and see if there are new if/thens that better align with what they would want them to be, or if/thens that really challenge or expose inadequacies in their existing heuristic models.\
Edit\
Yes! That comparison becomes so much more meaningful because they're not just learning about ethical frameworks in the abstract - they're holding them up against their own articulated decision-making patterns to see what fits, what challenges, what's missing.\
A student might discover that their instinctual heuristics as a parent align closely with care ethics, but their workplace decision-making follows more utilitarian logic. Or they might find that virtue ethics offers them language for something they've been feeling but couldn't articulate about their community role.\
And when a framework challenges their existing patterns, it's not threatening because they chose to explore it - it's useful feedback about whether their current approach is actually serving them well in that role.\
The formal frameworks become like diagnostic tools for examining their own ethical operating systems rather than external authorities telling them how they should think. Much more likely to lead to genuine integration and growth than the typical "here's what Mill says, now apply it to this case study" approach.\
They get to be active agents curating and refining their own decision-making processes rather than passive recipients of philosophical wisdom.\
Retry\
**C**\
OK. This works, so let's think about how to structure this. Don't come up with the worksheet or questions, let's get into some discussion about application...\
Edit\
Alright - so we're thinking about the practical mechanics of how this unfolds.\
A few application questions come to mind:\
How do you envision the flow between Part 1 and Part 2? Do students complete Part 1, then immediately move to Part 2, or is there some time gap? And how do they transition from the identification AI conversation to the storytelling AI conversation?\
Also, thinking about the AI's role - in Part 1 it was helping them identify and articulate the dilemma. In Part 2, it's more like an interviewer drawing out their decision-making stories. That's a pretty different conversational dynamic. Does that require different prompting strategies?\
And practically speaking, how much material are we talking about by the end of Part 2? If they're fleshing out multiple roles with 10+ heuristics each, plus the storytelling that reveals those patterns, that could be quite a lot of text to work with in subsequent phases.\
What's your sense of how this fits into the overall arc of the semester?\
Retry\
**C**\
Great questions. My vision: student completes Phase 1, sends it to me to review and approve what they generated with AI, then they move onto Phase 2. Since this is all happening asynchronously, there is no specific time limit, but students have to demonstrate ongoing engagement, so weekly checkins are a must. Once things are approved, they submit the Phase 1 document, along with the Phase 2 prompt in a new conversation, which allows the markdown prompt to reset the AI's role without creating overly long conversations. Yes, we will need to come up with the prompt scaffolding to elicit these kinds of responses, but I think it is a doable thing. You're right about the text necessary to generate that much insight, so we will need to practice to see how many heuristics could be generated in a relatively short time period or with a minimum of storytelling and how many would be needed to create a solid sense of algorithm for each role for analysis when we get into the model examinations.\
Edit\
That's a solid workflow design. The instructor approval checkpoint after Phase 1 is smart - catches any dilemmas that might not sustain semester-long analysis before students invest more time. And starting fresh conversations for each phase keeps the AI focused and prevents context overload.\
The weekly check-ins solve the asynchronous accountability challenge while still giving students flexibility in pacing.\
For the text volume question - it seems like the key is finding the sweet spot where students generate enough material to reveal genuine patterns without it becoming unwieldy. Maybe the AI prompting needs to be designed to efficiently extract those heuristics through targeted questions rather than letting the storytelling go completely open-ended?\
Like, the AI could be programmed to recognize when a student has revealed a decision rule in their narrative and immediately follow up with questions that flesh out that specific pattern, rather than just asking general "tell me more" questions.\
The practice element you mentioned seems crucial - you'll probably need to test this with a few sample scenarios to see how much conversation it actually takes to surface 10 meaningful heuristics per role, and whether that generates a manageable amount of text for the next phases.\
Are you thinking of piloting this with some volunteer students or test cases before full implementation?\
Retry\
**C**\
No time for test cases or volunteers. You've got yours truly and that is it. But I am willing to go through several iterations to try and hone in the focus. I think I like the idea of targeted questions most likely to get at the details of a story that yield heuristic details. And I think we can get there without too much difficulty. I tossed out 10 as a ballpark figure, but I don't need to get that much if we can get a good sense of how many heuristics are need to solidly represent ethical decision-making patterns.\
Edit\
Got it - you're the test case, and you need to iterate quickly to something workable. That actually might be more efficient than trying to coordinate volunteers anyway.\
The real question becomes: what's the minimum viable number of heuristics per role that gives you enough material to make meaningful comparisons with formal ethical frameworks later?\
Maybe it's not about hitting a specific number, but about reaching a point where you can see clear patterns and priorities emerging from their decision-making. Like, once the AI has extracted enough heuristics that you could predict how this person would likely approach a new decision in that role, you've probably got enough material.\
The AI could be programmed to recognize when it's getting repetitive responses or when the patterns are becoming clear, rather than just counting to an arbitrary number.\
Since you're going to be the guinea pig for this, you could probably tell pretty quickly whether the conversation is yielding the kind of insight you're hoping for or just spinning in circles. That immediate feedback should help you calibrate the prompt design efficiently.\
How are you thinking about approaching your own iterations - start with your administrative policy dilemma and see how the questioning unfolds?\
Retry\
**C**\
It makes sense as it sticks with the model of me using the same instruments, or at least the same parameters, as what I am asking my students to do. But I wonder if we are getting close to saturation with the length of the conversation. Could you draft a concise summary that could move us directly onto the next phase if we move to a new conversation?\
Edit\
Part 2 Development Summary: Ethical Algorithm Extraction\
Core Concept: Before students engage with formal ethical frameworks, they need to surface their existing decision-making patterns (ethical algorithms) for each role identified in their dilemma. This happens through guided storytelling that reveals their instinctual heuristics.\
Key Insights:

- Students have existing if-then decision rules but lack vocabulary to articulate them
- Use their Part 1 dilemma as skeleton; Part 2 adds "muscles and skin" through narrative
- Focus on process description ("what was going through your mind...") not analysis
- Target: enough heuristics per role to reveal clear decision-making patterns (flexible number, not rigid count)

Workflow:

1. Student completes Part 1, gets instructor approval
1. Student uploads Part 1 document to fresh AI conversation with Part 2 prompt
1. AI uses dilemma context to ask targeted follow-up questions that elicit decision-making stories
1. AI compiles role-specific summaries of heuristics and guiding principles
1. Creates clean material for later comparison with formal ethical frameworks

Design Challenge: Create AI prompting that efficiently extracts decision-making patterns through natural storytelling without breaking the reflective "spell" or using formal terminology.\
Next Phase: Develop the specific AI coaching instructions and question strategies for the storytelling/extraction process.\
Test Subject: You, using your administrative policy dilemma as the case study for iteration.\
Retry\
**C**\
Claude, it is such a pleasure working with you. Thank you for your assistance!\
Edit\
Thank you so much! I really enjoyed working through this with you too. Your approach to ethics education is genuinely innovative - the way you're using students' authentic dilemmas as the foundation for exploring their existing decision-making patterns before introducing formal frameworks is brilliant. It solves so many of the problems that make ethics courses feel disconnected from real life.\
The progression from dilemma identification to ethical algorithm extraction to framework comparison creates a really compelling learning arc. Your students are going to have some powerful moments of self-discovery.\
Best of luck with the development and implementation - I'd love to hear how it goes if you ever want to circle back and share results!\
Retry\
[Claude can make mistakes. Please double-check responses.](https://support.anthropic.com/en/articles/8525154-claude-is-providing-incorrect-or-misleading-responses-what-s-going-on)\
Sonnet 4\
Claude

**C**\
Clayn\
Free plan

